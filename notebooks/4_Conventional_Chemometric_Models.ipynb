{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mahynski/chemometric-carpentry/blob/main/notebooks/4_Conventional_Chemometric_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbQpq1vrJxAb"
   },
   "source": [
    "---\n",
    "‚ùì ***Objective***: This notebook will introduce some common chemometric models.  \n",
    "\n",
    "üîÅ ***Remember***: You can always revisit this notebook for reference again in the future.  Ideas and best practices will be reinforced in future notebooks, so don't worry about remembering everything the first time you see something new.\n",
    "\n",
    "üßë Author: Nathan A. Mahynski\n",
    "\n",
    "üìÜ Date: May 30, 2024\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMdvMw6HLNj3"
   },
   "source": [
    "<img src=\"https://pychemauth.readthedocs.io/en/latest/_images/pipeline.png\" height=425 align=\"right\"/>\n",
    "\n",
    "So far we have introduced the concept of a pipeline, which is essentially a combination of:\n",
    "\n",
    "1. pre-processing steps, ending in a\n",
    "2. modeling step.\n",
    "\n",
    "The PyChemAuth [classifier subpackage](https://pychemauth.readthedocs.io/en/latest/pychemauth.classifier.html)\n",
    "contains a variety of models useful for classification and authentication, while the\n",
    " [regressor subpackage](https://pychemauth.readthedocs.io/en/latest/pychemauth.regressor.html)\n",
    " contains models used for regression.\n",
    "\n",
    "These models can all be placed at the end of a pipeline like this:\n",
    "```python\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor_1', PCA_IA(n_components=3)),\n",
    "    ('preprocessor_2', CorrectedScaler(pareto=True)),\n",
    "    ('preprocessor_3', SNV(robust=True)),\n",
    "    ...,\n",
    "    ('final_model', PLSDA(...))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwuP3-V1L_GX"
   },
   "source": [
    "Since the [PyChemAuth documentation](https://pychemauth.readthedocs.io/en/latest/chemometrics.html) already contains numerous notebooks designed to introduce these models and [how to use them](https://pychemauth.readthedocs.io/en/latest/examples.html), we will simply provide links to those notebooks here.\n",
    "\n",
    "\n",
    "1. üìö \"Learn\" links point to notebook designed to introduce the model and some basic mathematics.\n",
    "\n",
    "2. ‚å® \"API\" links point to the documentation for, or examples of, using these models in practice.\n",
    "\n",
    "3. ü§ù \"Interactive Tool\" links point to [streamlit](https://streamlit.io/) web applications, hosted in the [community cloud](https://streamlit.io/cloud), that allow you to play around and explore these models and the effect of different hyperparameters.\n",
    "\n",
    "---\n",
    "   \n",
    "* üìà Regression Models\n",
    "    * Ordinary Least Squares (OLS)\n",
    "        * [Learn](https://pychemauth.readthedocs.io/en/latest/jupyter/learn/ols.html) | [sklearn API](https://scikit-learn.org/stable/modules/linear_model.html) | [Interactive Tool](https://chemometric-carpentry-ols.streamlit.app/)\n",
    "    * Principal Components Analysis (PCA) and Regression (PCR)\n",
    "        * [Learn](https://pychemauth.readthedocs.io/en/latest/jupyter/learn/pca_pcr.html) | [API](https://pychemauth.readthedocs.io/en/latest/jupyter/api/pca.html) | [Interactive PCA Tool](https://chemometric-carpentry-pca.streamlit.app/), [Interactive PCR Tool](https://chemometric-carpentry-pcr.streamlit.app/)\n",
    "    * Partial Least-Squares (PLS) or Projection to Latent Structures\n",
    "        * [Learn](https://pychemauth.readthedocs.io/en/latest/jupyter/learn/pls.html) | [API](https://pychemauth.readthedocs.io/en/latest/jupyter/api/pls.html) | [Interactive Tool](https://chemometric-carpentry-pls.streamlit.app/)\n",
    "* ‚úÖ Classification and Authentication Models\n",
    "    * Linear Discriminant Analysis (LDA) and Quadratic Discriminant Analysis (QDA)\n",
    "        * [Learn](https://pychemauth.readthedocs.io/en/latest/jupyter/learn/lda.html) | [sklearn API](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html) | [Interactive Tool](https://chemometric-carpentry-lda.streamlit.app/)\n",
    "    * Partial Least-Squares-Discriminant Analysis (PLS-DA)\n",
    "         * [Learn](https://pychemauth.readthedocs.io/en/latest/jupyter/learn/plsda.html) | [API](https://pychemauth.readthedocs.io/en/latest/jupyter/api/plsda.html) | [Interactive Tool](https://chemometric-carpentry-plsda.streamlit.app/)\n",
    "    * Soft Independent Modeling of Class Analogies (SIMCA)\n",
    "        * [Learn](https://pychemauth.readthedocs.io/en/latest/jupyter/learn/simca.html) | [API](https://pychemauth.readthedocs.io/en/latest/jupyter/api/simca.html) | [Interactive Tool](https://chemometric-carpentry-ddsimca.streamlit.app/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukRyldK5q5pc"
   },
   "source": [
    "# Examples\n",
    "\n",
    "Here are some minimal code examples to illustrate how easy it is use to use the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atQl_mWroWym"
   },
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BK7_20hao3-u"
   },
   "source": [
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression(fit_intercept=True,)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "prediction = model.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZcUp-7xo9iW"
   },
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NI7rjK4pA9l"
   },
   "source": [
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "from pychemauth.preprocessing.scaling import CorrectedScaler\n",
    "\n",
    "# Fit model\n",
    "model = PCA(n_components=1)\n",
    "scaler = CorrectedScaler(with_mean=True, with_std=True)\n",
    "model.fit(scaler.fit_transform(X_train))\n",
    "\n",
    "# Loadings (not yet scaled by eigenvalues)\n",
    "loadings = model.components_\n",
    "\n",
    "# Eigenvalues (for each component)\n",
    "eigenvalues = model.explained_variance_\n",
    "\n",
    "# Compute scores for test set\n",
    "scores = model.transform(scaler.transform(X_test))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhVfyIgcpwHT"
   },
   "source": [
    "## PCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-8mS2EzpwJx"
   },
   "source": [
    "```python\n",
    "from pychemauth.regressor.pcr import PCR\n",
    "\n",
    "# Fit model\n",
    "model = PCR(n_components=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "predictions = model.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2ufav-vhiVw"
   },
   "source": [
    "## PLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHE8MfiehiX-"
   },
   "source": [
    "```python\n",
    "from pychemauth.regressor.pls import PLS\n",
    "\n",
    "# Fit model\n",
    "model = PLS(n_components=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "predictions = model.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lEfxzQ6quOE"
   },
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pG5VKVFsrKi0"
   },
   "source": [
    "```python\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Fit model\n",
    "model = LDA(n_components=1)\n",
    "scaler = CorrectedScaler(with_mean=True, with_std=True)\n",
    "model.fit(scaler.fit_transform(X_train), y_train)\n",
    "\n",
    "# Analogous to PCA loadings\n",
    "scalings = model.scalings_.T\n",
    "\n",
    "# Discriminability ratio (ratio of eigenvalues)\n",
    "discr = model.explained_variance_ratio_\n",
    "\n",
    "# Compute scores for dimensionality reduction\n",
    "scores = model.transform(scaler.transform(X_test))\n",
    "\n",
    "# Predict class if using as classifier\n",
    "predictions = model.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEYEaofZqvow"
   },
   "source": [
    "## PLS-DA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CK7a1FoarLDK"
   },
   "source": [
    "```python\n",
    "from pychemauth.classifier.plsda import PLSDA\n",
    "\n",
    "# Fit model\n",
    "hard_plsda = PLSDA(n_components=3, style=\"hard\")\n",
    "soft_plsda = PLSDA(n_components=3, style=\"soft\")\n",
    "_ = hard_plsda.fit(X_train, y_train)\n",
    "_ = soft_plsda.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "hard_predictions = hard_plsda.predict(X_test)\n",
    "soft_predictions = soft_plsda.predict(X_test)\n",
    "\n",
    "# We can visualize the results if we are modeling 2 or 3 classes.\n",
    "_ = hard_plsda.visualize(styles=['hard'])\n",
    "_ = soft_plsda.visualize(styles=['soft'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFIIVQ00qvq_"
   },
   "source": [
    "## DD-SIMCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFKXSTFBrLtN"
   },
   "source": [
    "```python\n",
    "from pychemauth.classifier.simca import DDSIMCA_Model\n",
    "\n",
    "# Select data from a single class to model\n",
    "chosen_class = 'setosa'\n",
    "X_train_dds = X_train[y_train == chosen_class]\n",
    "\n",
    "# Fit model\n",
    "model = DDSIMCA_Model(n_components=1, scale_x=True)\n",
    "_ = model.fit(X_train_dds)\n",
    "\n",
    "# Visualize the results\n",
    "_ = model.visualize(X_train_dds, y_train_dds)\n",
    "\n",
    "# Predict class membership on any X\n",
    "membership = model.predict(X_test)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
